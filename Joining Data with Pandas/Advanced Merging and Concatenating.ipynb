{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Joins\n",
    "\n",
    "**Mutating versus filtering joins**  \n",
    "Mutating joins:  \n",
    "Combines data from two tables based on matching observations in both tables  \n",
    "Filtering joins:  \n",
    "Filter observations from table based on whether or not they match an observation in another table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Joins\n",
    "\n",
    "\n",
    "Step 1 - Inner Join  \n",
    "Merge the two tables with an inner join.   \n",
    ">genres_tracks = genres.merge(top_tracks, on='gid') \n",
    "\n",
    "Step 2 - semi-join \n",
    "This line of code returns a Boolean Series of true or false values.\n",
    "> genres['gid'].isin(genres_tracks['gid'])  \n",
    "\n",
    "Uses a method called isin(), which compares every 'gid' in the genres table to the 'gid' in the genres_tracks table.  \n",
    "This will tell us if our genre appears in our merged genres_tracks table.  \n",
    "\n",
    "Step 3 - semi-join\n",
    ">genres_tracks = genres.merge(top_tracks, on='gid')  \n",
    ">top_genres = genres[genres['gid'].isin(genres_tracks['gid'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti-join\n",
    "Anti-Joins return the observations in the left table that do not have a matching observation in the right table.  \n",
    "It also only returns the columns from the left table. \n",
    "\n",
    "Step 1\n",
    "Use a left join returning all of the rows from the left table.  \n",
    ">genres_tracks = genres.merge(top_tracks, on='gid', how='left', indicator=True)\n",
    "\n",
    "With indicator set to True, the merge method adds a column called \"_merge\" to the output.  \n",
    "This column tells the source of each row. \n",
    "\n",
    "Step 2  \n",
    "Use the \"loc\" accessor and \"_merge\" column to select the rows that only appeared in the left table and return only the \"gid\" column from the genres_tracks table.  \n",
    "We now have a list of gids not in the tracks table.\n",
    "\n",
    ">gid_list = genres_tracks.loc[genres_tracks['_merge'] == 'left_only','gid']\n",
    "\n",
    "Step 3  \n",
    "Use the isin() method to filter for the rows with gids in our gid_list.  \n",
    "Our output shows those genres not in the tracks table.  \n",
    ">gid_list = genres_tracks.loc[genres_tracks['_merge'] == 'left_only','gid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps of a semi-join\n",
    "In the last video, you were shown how to perform a semi-join with pandas.  \n",
    "Recall that a semi-join filters the left table to only the rows where a match exists in both the left and right tables.\n",
    "\n",
    "Sort the steps in the correct order of the technique shown to perform a semi-join in pandas.  \n",
    "Merge the left and right tables on key column using an inner join.  \n",
    "Search if the key column in the left table is in the merged table susing the .isin() methond creating a Boolean series.  \n",
    "Subset the rows of the left table.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing an anti-join\n",
    "In our music streaming company dataset, each customer is assigned an employee representative to assist them.  \n",
    "In this exercise, filter the employee table by a table of top customers, returning only those employees who are not assigned to a customer.  \n",
    "The results should resemble the results of an anti-join.  \n",
    "The company's leadership will assign these employees additional training so that they can work with high valued customers.  \n",
    "\n",
    "The top_cust and employees tables have been provided for you.  \n",
    "\n",
    "Merge employees and top_cust with a left join, setting indicator argument to True. Save the result to empl_cust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "top_cust = pd.read_csv('top_cust.csv')\n",
    "employees = pd.read_csv('employees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_cust = employees.merge(top_cust, on = 'srid', how = 'left', indicator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the srid column of empl_cust and the rows where _merge is 'left_only'. Save the result to srid_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the srid column where _merge is left_only\n",
    "srid_list = empl_cust.loc[empl_cust['_merge'] == 'left_only', 'srid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the employees table and select those rows where the srid is in the variable srid_list and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   srid     lname    fname            title   hire_date  \\\n",
      "0     1     Adams   Andrew  General Manager   8/14/2002   \n",
      "1     2   Edwards    Nancy    Sales Manager    5/1/2002   \n",
      "5     6  Mitchell  Michael       IT Manager  10/17/2003   \n",
      "6     7      King   Robert         IT Staff    1/2/2004   \n",
      "7     8  Callahan    Laura         IT Staff    3/4/2004   \n",
      "\n",
      "                     email  \n",
      "0   andrew@chinookcorp.com  \n",
      "1    nancy@chinookcorp.com  \n",
      "5  michael@chinookcorp.com  \n",
      "6   robert@chinookcorp.com  \n",
      "7    laura@chinookcorp.com  \n"
     ]
    }
   ],
   "source": [
    "# Get employees not working with top customers\n",
    "print(employees[employees['srid'].isin(srid_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a semi-join\n",
    "Some of the tracks that have generated the most significant amount of revenue are from TV-shows or are other non-musical audio.  \n",
    "You have been given a table of invoices that include top revenue-generating items.  \n",
    "Additionally, you have a table of non-musical tracks from the streaming service.  \n",
    "In this exercise, you'll use a semi-join to find the top revenue-generating non-musical tracks.  \n",
    "\n",
    "The tables non_mus_tcks, top_invoices, and genres have been loaded for you.  \n",
    "\n",
    "Merge non_mus_tcks and top_invoices on tid using an inner join. Save the result as tracks_invoices.  \n",
    "Use .isin() to subset the rows of non_mus_tck where tid is in the tid column of tracks_invoices. Save the result as top_tracks.  \n",
    "Group top_tracks by gid and count the tid rows. Save the result to cnt_by_gid.  \n",
    "Merge cnt_by_gid with the genres table on gid and print the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_mus_tcks = pd.read_csv('non_mus_tcks.txt', sep='\\t')\n",
    "top_invoices = pd.read_csv('top_invoices.tsv', sep='\\t')\n",
    "genres = pd.read_csv('genres.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gid  tid      name\n",
      "0   19    4  TV Shows\n",
      "1   21    2     Drama\n",
      "2   22    1    Comedy\n"
     ]
    }
   ],
   "source": [
    "# Merge the non_mus_tck and top_invoices tables on tid\n",
    "tracks_invoices = non_mus_tcks.merge(top_invoices, on = 'tid', how = 'inner')\n",
    "\n",
    "# Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n",
    "top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
    "\n",
    "# Group the top_tracks by gid and count the tid rows\n",
    "cnt_by_gid = top_tracks.groupby(['gid'], as_index = False).agg({'tid':'count'})\n",
    "\n",
    "# Merge the genres table to cnt_by_gid on gid and print\n",
    "print(cnt_by_gid.merge(genres, on = 'gid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate DataFrames Together Vertically\n",
    "\n",
    "**Basic concatenation**  \n",
    ">pd.concat([inv_jan, inv_feb, inv_mar])  \n",
    "\n",
    "**Ignoring the index**  \n",
    ">pd.concat([inv_jan, inv_feb, inv_mar],ignore_index=True)  \n",
    "\n",
    "**Setting labels to original tables**  \n",
    ">pd.concat([inv_jan, inv_feb, inv_mar],  \n",
    "        ignore_index=False,  \n",
    "        keys=['jan','feb','mar'])\"  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate tables with different column names\n",
    "The concat method by default will include all of the columns in the different tables it's combining.  \n",
    "The sort argument, if true, will alphabetically sort the different column names in the result.  \n",
    "\n",
    ">pd.concat([inv_jan, inv_feb],sort=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate tables with different column names 2\n",
    "To return only  the matching columns between tables, set the join argument to \"inner\".  \n",
    "The default value is equal to \"outer\", which is why concat by default will include all of the columns.  \n",
    "Additionally, the sort argument has no effect when join equals \"inner\". The order of the columns will be the same as the input tables.  \n",
    "\n",
    "> pd.concat([inv_jan, inv_feb],join='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using append method\n",
    ".append()\n",
    "Simplified concat method  \n",
    "Supports 'ignore_index' and 'sort'  \n",
    "Does not support 'keys' and 'join'  \n",
    "Always 'join = outer'\n",
    "\n",
    ">inv_jan.append([inv_feb, inv_mar],  \n",
    "                ignore_index=True,  \n",
    "                sort=True)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation basics\n",
    "You have been given a few tables of data with musical track info for different albums from the metal band, Metallica.  \n",
    "The track info comes from their Ride The Lightning, Master Of Puppets, and St. Anger albums.  \n",
    "Try various features of the .concat() method by concatenating the tables vertically together in different ways.  \n",
    "\n",
    "The tables tracks_master, tracks_ride, and tracks_st have loaded for you.  \n",
    "\n",
    "Concatenate tracks_master, tracks_ride, and tracks_st, in that order, setting sort to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_master = pd.read_csv('tracks_master.tsv', sep='\\t')\n",
    "tracks_ride = pd.read_csv('tracks_ride.tsv', sep='\\t')\n",
    "tracks_st = pd.read_csv('tracks_st.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aid             composer  gid  mtid                     name      tid  \\\n",
      "0   52  J.Hetfield/L.Ulrich    3     1               Battery  1  0  1853   \n",
      "1   52            K.Hammett    3     1     Master Of Puppets  1  1  1854   \n",
      "2   52  J.Hetfield/L.Ulrich    3     1     Disposable Heroes  1  4  1857   \n",
      "0  154                  NaN    3     1     Fight Fire With Fire     1874   \n",
      "1  154                  NaN    3     1       Ride The Lightning     1875   \n",
      "2  154                  NaN    3     1  For Whom The Bell Tolls     1876   \n",
      "3  154                  NaN    3     1            Fade To Black     1877   \n",
      "4  154                  NaN    3     1        Trapped Under Ice     1878   \n",
      "0  155                  NaN    3     1                  Frantic     1882   \n",
      "1  155                  NaN    3     1                St. Anger     1883   \n",
      "2  155                  NaN    3     1     Some Kind Of Monster     1884   \n",
      "3  155                  NaN    3     1             Dirty Window     1885   \n",
      "4  155                  NaN    3     1            Invisible Kid     1886   \n",
      "\n",
      "   u_price  \n",
      "0     0.99  \n",
      "1     0.99  \n",
      "2     0.99  \n",
      "0     0.99  \n",
      "1     0.99  \n",
      "2     0.99  \n",
      "3     0.99  \n",
      "4     0.99  \n",
      "0     0.99  \n",
      "1     0.99  \n",
      "2     0.99  \n",
      "3     0.99  \n",
      "4     0.99  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate the tracks\n",
    "\n",
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st], sort = True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate tracks_master, tracks_ride, and tracks_st, where the index goes from 0 to n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aid  gid  mtid                     name      tid  u_price\n",
      "0   52    3     1               Battery  1  0  1853     0.99\n",
      "1   52    3     1     Master Of Puppets  1  1  1854     0.99\n",
      "2   52    3     1     Disposable Heroes  1  4  1857     0.99\n",
      "0  154    3     1     Fight Fire With Fire     1874     0.99\n",
      "1  154    3     1       Ride The Lightning     1875     0.99\n",
      "2  154    3     1  For Whom The Bell Tolls     1876     0.99\n",
      "3  154    3     1            Fade To Black     1877     0.99\n",
      "4  154    3     1        Trapped Under Ice     1878     0.99\n",
      "0  155    3     1                  Frantic     1882     0.99\n",
      "1  155    3     1                St. Anger     1883     0.99\n",
      "2  155    3     1     Some Kind Of Monster     1884     0.99\n",
      "3  155    3     1             Dirty Window     1885     0.99\n",
      "4  155    3     1            Invisible Kid     1886     0.99\n"
     ]
    }
   ],
   "source": [
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st], join = 'inner', sort = True)\n",
    "print(tracks_from_albums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate tracks_master, tracks_ride, and tracks_st, showing only columns that are in all tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st], ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating with keys\n",
    "The leadership of the music streaming company has come to you and asked you for assistance in analyzing sales for a recent business quarter.  \n",
    "They would like to know which month in the quarter saw the highest average invoice total.  \n",
    "You have been given three tables with invoice data named inv_jul, inv_aug, and inv_sep.  \n",
    "Concatenate these tables into one to create a graph of the average monthly invoice total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the tables and add keys\n",
    "inv_jul_thr_sep = pd.concat([inv_jul, inv_aug, inv_sep], \n",
    "                            keys=['7Jul', '8Aug', '9Sep'])\n",
    "\n",
    "# Group the invoices by the index keys and find avg of the total column\n",
    "avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total':'mean'})\n",
    "\n",
    "# Bar plot of avg_inv_by_month\n",
    "avg_inv_by_month.plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the append method\n",
    "The .concat() method is excellent when you need a lot of control over how concatenation is performed. However, if you do not need as much control, then the .append() method is another option. You'll try this method out by appending the track lists together from different Metallica albums. From there, you will merge it with the invoice_items table to determine which track sold the most.\n",
    "\n",
    "The tables tracks_master, tracks_ride, tracks_st, and invoice_items have loaded for you.  \n",
    "\n",
    "Use the .append() method to combine (in this order)tracks_ride, tracks_master, and tracks_st together vertically, and save to metallica_tracks.  \n",
    "Merge metallica_tracks and invoice_items on tid with an inner join, and save to tracks_invoices.  \n",
    "For each tid and name in tracks_invoices, sum the quantity sold column, and save as tracks_sold.  \n",
    "Sort tracks_sold in descending order by the quantity column, and print the table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .append() method to combine the tracks tables\n",
    "metallica_tracks = tracks_ride.append([tracks_master, tracks_st], sort = False)\n",
    "\n",
    "# Merge metallica_tracks and invoice_items\n",
    "tracks_invoices = metallica_tracks.merge(invoice_items, on = 'tid', how = 'inner')\n",
    "\n",
    "# For each tid and name sum the quantity sold\n",
    "tracks_sold = tracks_invoices.groupby(['tid','name']).agg({'quantity':'sum'})\n",
    "\n",
    "# Sort in decending order by quantity and print the results\n",
    "print(tracks_sold.sort_values('quantity', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying Integrity\n",
    "\n",
    "The validate and verify_integrity arguments of the merge and concat methods respectively will allow us to verify the data.  \n",
    "\n",
    ".merge(validate=None) : Checks if merge is of specified type\n",
    "\n",
    ">tracks.merge(specs, on='tid',validate='one_to_one')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying concatenations\n",
    ".concat(verify_integrity=False) : Check whether the new concatenated index contains duplicates  \n",
    "Default value is False\n",
    "\n",
    ">pd.concat([inv_feb, inv_mar],verify_integrity=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why verify integrity and what to do  \n",
    "Why:  \n",
    "Real world data is often not clean  \n",
    "What to do:  \n",
    "Fix incorrect data  \n",
    "Drop Duplicate Rows "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
